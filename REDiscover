#!/usr/bin/env python
desc="""Identify RNA editing sites from RNAseq and DNAseq alignements (.bam).

-s / --stranded optimised for Illumina type stranded protocols

TBD:
- rescue major alt haplotype if the other is only very low freq!!
- use read1/2 in --stranded, so far only using read1
- on indels removal from read, make sure to strip quals properly!
"""
epilog="""Author:
l.p.pryszcz@gmail.com

Warsaw/Bratislava, 21/07/2015
"""

import os, re, sys, resource
from datetime import datetime
from multiprocessing import Pool
import subprocess
import numpy as np
    
# http://samtools.sourceforge.net/pileup.shtml
read_start_pat = re.compile('\^.')
indel_pat = re.compile('[+-]\d+')

def _remove_indels(alts, toSkip={'^', '$', '*', '<', '>'}):
    """Remove not-base info from mpileup genotype."""
    # here I should keep mapQ only from kept bases, while all are kept!
    alts = "".join(b for bases in read_start_pat.split(alts) for b in bases if b not in toSkip)
    # remove indels info
    m = indel_pat.search(alts)
    while m:
        pos = m.end() + int(m.group()[1:])
        alts = alts[:m.start()] + alts[pos:]
        m = indel_pat.search(alts, m.start())
    return alts

def get_major_alleles(cov, alts, minFreq, alphabet="ACGT", minCount=3):
    """Return major alleles that passed filtering and their frequencies."""
    bases, freqs = [], []
    for base_count, base in zip((alts.upper().count(b) for b in alphabet), alphabet):
        # skip if alt base calling if less than 3 reads
        if base_count < minCount:
            continue
        freq = base_count*1.0/cov
        #check freq
        if freq < minFreq:
            continue
        bases.append(base)
        freqs.append(freq)
    return bases, freqs

def concatenate_mpileup(data):
    """Concatenate mpileup from multiple samples / replicas"""
    cov, algs, quals = 0, [], []
    for _cov, _algs, _quals in zip(data[0::3], data[1::3], data[2::3]):
        if int(_cov):
            cov += int(_cov)
            algs.append(_algs)
            quals.append(_quals)
    return cov, "".join(algs), "".join(quals)

def get_meanQ(quals, offset=33):
    """Return mean quality"""
    return np.mean([ord(q)-offset for q in quals])

def genotypes2stranded(genotypes):
    """Split coverage, basecalls and qualities into forward and reverse strand"""
    forward, reverse = [], []
    for cov, bases, quals in zip(genotypes[0::3], genotypes[1::3], genotypes[2::3]):
        fbases, fquals, rbases, rquals = [], [], [], []
        for b, q in zip(bases, quals):
            if b in set('.ACGTN'):
                fbases.append(b)
                fquals.append(q)
            elif b in set(',acgtn'):
                rbases.append(b)
                rquals.append(q)
            else:
                sys.stderr.write("[WARNING] Cannot guess the strand: %s %s\n"%(b, bases))
        # store
        forward += [len(fbases), "".join(fbases), "".join(fquals)]
        reverse += [len(rbases), "".join(rbases), "".join(rquals)]
    return forward, reverse
    
def stranded_parser(handle, dna, stranded, minDepth, minDNAfreq):
    """Split mpileup output into forward and reverse strand information"""
    lineTuple = []
    for line in handle:
        if len(line.split('\t'))<3:
            sys.stderr.write("[ERROR] Cannot parse line %s. Before: %s\n"%(str(line.split('\t')), lineTuple))
            continue
        # unload line
        lineTuple = line[:-1].split('\t')
        posinfo, genotypes = lineTuple[:3], lineTuple[3:]
        contig, pos, baseRef = posinfo
        
        # skip if low coverage; note it'll be done 2nd time later, for stranded rnaseq
        altcov = sum(int(x) for x in genotypes[3*len(dna)::3])
        if altcov < minDepth:
            continue
            
        # genotype ref from BAM
        if dna:
            refcov = sum(int(x) for x in genotypes[:3*len(dna):3])
            if refcov < minDepth:
                continue
            # unload ref and sample data
            refData = lineTuple[3:3+3*len(dna)]
            genotypes = lineTuple[3+3*len(dna):]
            # remove indels from ref
            for i in range(1, len(refData), 3):
                refData[i] = _remove_indels(refData[i])
            # concatenate
            refCov, refAlgs, refQuals = concatenate_mpileup(refData)
            baseRef, refFreq = get_major_alleles(refCov, refAlgs, minDNAfreq)
            if not baseRef:
                continue
            # mean qual
            gmeanQ = get_meanQ(refQuals)
        # use reference fasta
        else:
            refFreq, refCov, gmeanQ = [1.0], 100, 40.0
            baseRef = baseRef.upper()
            if baseRef not in "ACGT":
                continue
                
        # remove indels from samples
        for i in range(1, len(genotypes), 3):
            genotypes[i] = _remove_indels(genotypes[i])
            
        # split stranded and yield forward and reverse reads separately
        if stranded:
            forward, reverse = genotypes2stranded(genotypes)
            yield contig, pos, "-", baseRef, refCov, gmeanQ, refFreq, forward
            yield contig, pos, "+", baseRef, refCov, gmeanQ, refFreq, reverse
        else:
            yield contig, pos, ".", baseRef, refCov, gmeanQ, refFreq, genotypes
                
def parse_mpileup(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mpileup_opts,
                  verbose=0, region=''):
    """Run mpileup subprocess and parse output."""
    #open subprocess
    args = ['samtools', 'mpileup']
    if region:
        args += ["-r", str(region)]
    if not dna:
        args += ["-f", fasta]
    args += mpileup_opts.split() + dna + rna 
    if verbose:
        sys.stderr.write(" %s\n" % " ".join(args))
    proc = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    parser = stranded_parser(proc.stdout, dna, stranded, minDepth, minDNAfreq)
    for contig, pos, strand, baseRef, refCov, gmeanQ, refFreq, samplesData in parser:
        # concatenate alts
        cov, alg, quals = concatenate_mpileup(samplesData) 
        cov = int(cov)
        if cov<minDepth:
            continue
            
        # check for SNP
        bases, freqs = get_major_alleles(cov, alg, minRNAfreq)
        if not bases or bases==baseRef:
            continue
        #print baseRef, refFreq, bases, freqs
        # remove ref base from alternative bases
        refBase = baseRef[0]
        if refBase in bases:
            idx = bases.index(refBase)
            freqs = freqs[:idx] + freqs[idx+1:]
            bases.remove(refBase)
        
        # rescue major alt haplotype if the other is only very low freq
        
        if len(baseRef) != 1 or len(bases) != 1:
            info = "[WARNING] Wrong number of bases: %s:%s %s %s\n"
            sys.stderr.write(info%(contig, pos, ",".join(baseRef), ",".join(bases)))
            continue
        # skip if the same base
        #if not bases.difference(baseRef):
        #    continue
        meanQ = get_meanQ(quals)
        yield (contig, pos, strand, refBase, bases.pop(), refCov, gmeanQ, refFreq[0], \
               cov, meanQ, freqs[0])

def init_args(*args):
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mpileup_opts, verbose
    dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mpileup_opts, verbose = args
    
def worker(args):
    """Count overlapping intervals with given read alignment.
    The algorithm support spliced alignments. """
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mpileup_opts, verbose
    region = args
    totdata = []
    for data in parse_mpileup(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq,
                              mpileup_opts, verbose, region=region):
        totdata.append(data)
    return totdata

def get_consecutive(data, stepsize=1):
    """Return consecutive windows allowing given max. step size"""
    return np.split(data, np.where(np.diff(data) > stepsize)[0]+1)
            
def get_covered_regions(bams, mincov=3, mapq=10, stranded=0, maxdist=16000, minsize=0):
    """Return chromosome regions covered by at least mincov reads cumulatively from all bam files.
    
    Regions distant less by maxdist will be collapsed. Make sure, maxdist is large enough,
    ie 16kb is typical linear index block size for sorted bam. 
    """
    import pysam
    sam = pysam.Samfile(bams[0])
    references, lengths = sam.references, sam.lengths
    for ref, length in zip(references, lengths):
        #if ref!="7": continue
        # store coverage
        coverage = np.zeros(length, dtype='uint16')
        for bam in bams:
            sam = pysam.Samfile(bam)
            for a in sam.fetch(reference=ref):
                # qc and skip read2 if stranded
                if a.mapq<mapq or a.is_duplicate or a.is_secondary or a.is_qcfail or a.is_supplementary \
                   or stranded and a.is_read2:
                    continue
                # add alg blocks
                for s, e in a.blocks:
                    coverage[s:e] += 1
        # get regions with coverage
        covered = np.where(coverage>=mincov)[0]
        for positions in get_consecutive(covered, maxdist):
            if len(positions)<1:
                continue
            s, e = positions[0]+1, positions[-1]+1
            if minsize and e-s<minsize:
                continue
            region = "%s:%s-%s"%(ref, s, e)
            yield region

def logger(info, add_timestamp=1, add_memory=1, out=sys.stderr):
    """Report nicely formatted stream to stderr"""
    memory = timestamp = ""
    if add_timestamp:
        timestamp = "[%s] "%datetime.ctime(datetime.now())
    if add_memory:
        memory = "[memory: %6i Mb]"%(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024, )
    out.write("%s%s%s\n"%(timestamp, info, memory))

def main():
    import argparse
    usage  = "%(prog)s [options]" 
    parser  = argparse.ArgumentParser(usage=usage, description=desc, epilog=epilog, \
                                      formatter_class=argparse.RawTextHelpFormatter)
    
    parser.add_argument("-v", "--verbose", default=False, action="store_true", help="verbose")    
    parser.add_argument('--version', action='version', version='1.14b')
    parser.add_argument("-o", "--output", required=True,  help="output file")
    parser.add_argument("-r", "--rna", nargs="+", 
                        help="input RNA-Seq BAM file(s)")
    refpar = parser.add_mutually_exclusive_group(required=True)
    refpar.add_argument("-d", "--dna", nargs="*", default = [], 
                        help="input DNA-Seq BAM file(s)")
    refpar.add_argument("-f", "--fasta", default = None, 
                        help="reference FASTA file")
    parser.add_argument("-s", "--stranded", default=False, action="store_true",
                        help="stranded RNAseq libraries")    
    parser.add_argument("--minDepth", default=5,  type=int,
                        help="minimal depth of coverage [%(default)s]")
    parser.add_argument("--minAltReads", default=3,  type=int,
                        help="minimum no. of reads with alternative base to call RNA editing [%(default)s]")
    parser.add_argument("--minRNAfreq",  default=0.01, type=float,
                        help="min frequency for RNA editing base [%(default)s]")
    parser.add_argument("--minDNAfreq",  default=0.99, type=float,
                        help="min frequency for genomic base [%(default)s]")
    parser.add_argument("-m", "--mapq", default=15, type=int, help="mapping quality [%(default)s]")
    parser.add_argument("--bcq", default=20, type=int, help="basecall quality [%(default)s]")
    parser.add_argument("-t", "--threads", default=1, type=int, help="number of cores to use [%(default)s]")
    
    # print help if no parameters
    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(1)
    o = parser.parse_args()
    if o.verbose:
        sys.stderr.write("Options: %s\n"%str(o))
    
    # check if all input files exists
    for fn in o.dna+o.rna:
        if not os.path.isfile(fn):
            sys.stderr.write("No such file: %s\n"%fn)
            sys.exit(1)

    # check if outfile exists and not empty
    if os.path.exists(o.output) and open(o.output).readline():
        sys.stderr.write("The output file %s exists!"%o.output)
        sys.exit(1)
    else:
        output = open(o.output, "w")
            
    # generate mpileup_opts
    mpileup_opts = ["-I", "-q", o.mapq, "-Q", o.bcq]
    # focus only on first read in pair
    ## this is valid for Illumina - in order to add support for another libs you will need to recognise them!
    if o.stranded:
        mpileup_opts.append("--rf 64")
    mpileup_opts = " ".join(map(str, mpileup_opts))

    runinfo = " ".join(sys.argv)
    header = "## %s\n# chr\tpos\tstrand\tref\talt\tref cov\tref Q\tref freq\talt cov\talt Q\talt freq\n"%runinfo
    output.write(header); output.flush()
    info = "%s\t"*10 + "%s\n" #"%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n"
    
    '''
    for data in parse_mpileup(o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, mpileup_opts, o.verbose):
        output.write(info%data)
    '''
    logger("Indexing bam file(s)...")
    for fn in o.dna + o.rna:
        if not os.path.isfile(fn+".bai"):
            cmd = "samtools index %s"%fn
            if o.verbose:
                sys.stderr.write(" %s\n"%cmd)
            os.system(cmd)
    
    logger("Generating regions...")
    regions = get_covered_regions(o.rna, o.minDepth, o.mapq, o.stranded)
    
    logger("Running samtools mpileup...")
    initargs = (o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, mpileup_opts, o.verbose)
    p = Pool(o.threads, initializer=init_args, initargs=initargs)
    parser = p.imap(worker, regions)
    for data in parser:
        output.write("".join(info%d for d in data))
    #'''
    output.write("#Finished!\n")
    logger("Done!")
    
if __name__=='__main__': 
    t0 = datetime.now()
    try:
        main()
    except KeyboardInterrupt:
        sys.stderr.write("\nCtrl-C pressed!      \n")
    except IOError as e:
        sys.stderr.write("I/O error({0}): {1}\n".format(e.errno, e.strerror))
    dt = datetime.now()-t0
    sys.stderr.write("#Time elapsed: %s\n" % dt)
