#!/usr/bin/env python
desc="""Identify RNA editing sites from RNAseq and DNAseq alignements (.bam).

-s / --stranded optimised for Illumina type stranded protocols

TBD:
- rescue major alt haplotype if the other is only very low freq!!
- speedup if DNAseq.bam by selecting intervals with reads from RNAseq
-- probably need bedtools for that
"""
epilog="""Author:
l.p.pryszcz@gmail.com

Warsaw/Bratislava, 21/07/2015
"""

import commands, os, re, sys
from datetime import datetime
from multiprocessing import Pool
import subprocess
import numpy as np
    
#find stats of the reads in mpileup
##http://samtools.sourceforge.net/pileup.shtml
read_start_pat = re.compile('\^.')
indel_pat = re.compile('[+-]\d+')

def _remove_indels(alts, toSkip={'^', '$', '*', '<', '>'}):
    """Remove not-base info from mpileup genotype."""
    # here I should keep mapQ only from kept bases, while all are kept!
    alts = "".join(b for bases in read_start_pat.split(alts) for b in bases if b not in toSkip)
    # remove indels info
    m = indel_pat.search(alts)
    while m:
        pos = m.end() + int(m.group()[1:])
        alts = alts[:m.start()] + alts[pos:]
        # get next match
        m = indel_pat.search(alts, m.start())
    return alts

def get_alt_allele(base_ref, cov, alg, minFreq, alphabet, reference, bothStrands):
    """Return alternative allele only if different than ref and freq >= minFreq."""
    #remove deletions
    alts = alg
    dels = alts.count('*') 
    #remove insertions
    #alts = _remove_indels(alts)
    #get base counts
    baseCounts = [(alts.upper().count(base), base) for base in alphabet]
    #get base frequencies
    for base_count, base in sorted(baseCounts):
        freq = base_count*1.0/len(alts)#cov
        if base!=base_ref and freq >= minFreq:
            #check if alt base in both strands
            if bothStrands: 
                if not base.upper() in alts or not base.lower() in alts:
                    return
            return (base, freq) # base!=base_ref and

def get_major_alleles(cov, alg, minFreq, alphabet, bothStrands, minCount=3):
    """Return major alleles that passed filtering and their frequencies."""
    #remove deletions
    alts = alg
    dels = alts.count('*') 
    #remove insertions
    alts = _remove_indels(alts)
    #get base frequencies
    bases, freqs = [], []
    for base_count, base in zip((alts.upper().count(b) for b in alphabet), alphabet):
        # skip if alt base calling if less than 3 reads
        if base_count < minCount:
            continue
        freq = base_count*1.0/cov
        #check freq
        if freq < minFreq:
            continue
        #check if alt base in both strands
        if bothStrands: 
            if not base.upper() in alts or not base.lower() in alts:
                continue
        bases.append(base)
        freqs.append(freq)
    return bases, freqs

def concatenate_mpileup(data):
    """Concatenate mpileup from multiple samples / replicas"""
    cov, algs, quals = 0, "", ""
    for _cov, _algs, _quals in zip(data[0::3], data[1::3], data[2::3]):
        cov += int(_cov)
        if int(_cov):
            algs  += _algs
            quals += _quals
    return cov, algs, quals

def get_meanQ(quals, offset=33):
    """Return mean quality"""
    return np.mean([ord(q)-offset for q in quals])

def genotypes2stranded(genotypes):
    """Split coverage, basecalls and qualities into forward and reverse strand"""
    forward, reverse = [], []
    for cov, bases, quals in zip(genotypes[0::3], genotypes[1::3], genotypes[2::3]):
        fbases, fquals, rbases, rquals = [], [], [], []
        for b, q in zip(bases, quals):
            # at this point I don't care about quals anymore!
            #if len(bases)!=len(quals):
            #    sys.stderr.write("[WARNING] Different length of bases and quals %s %s!\n"%(len(bases), len(quals)))
            if b in set('.ACGTN'):
                fbases.append(b)
                fquals.append(q)
            elif b in set(',acgtn'):
                rbases.append(b)
                rquals.append(q)
            else:
                sys.stderr.write("[WARNING] Cannot guess the strand: %s %s\n"%(b, bases))
        # store
        forward += [len(fbases), "".join(fbases), "".join(fquals)]
        reverse += [len(rbases), "".join(rbases), "".join(rquals)]
    return forward, reverse
    
def stranded_parser(handle, dna, stranded, mincov):
    """Split mpileup output into forward and reverse strand information"""
    lineTuple = []
    for line in handle:
        if len(line.split('\t'))<3:
            sys.stderr.write("[ERROR] Cannot parse line %s. Before: %s\n"%(str(line.split('\t')), lineTuple))
            continue
        lineTuple = line[:-1].split('\t')
        posinfo, genotypes = lineTuple[:3], lineTuple[3:]
        # skip if low coverage; note it'll be done 2nd time later, for stranded rnaseq
        altcov = sum(int(x) for x in genotypes[3*len(dna)::3])
        if altcov < mincov:
            continue
        if dna:
            refcov = sum(int(x) for x in genotypes[:3*len(dna):3])
            if refcov < mincov:
                continue
        # remove indels
        for i in range(1, len(genotypes), 3):
            genotypes[i] = _remove_indels(genotypes[i])
        # split stranded and yield forward and reverse reads separately
        if stranded:
            ref, genotypes = genotypes[:3*len(dna)], genotypes[3*len(dna):]
            forward, reverse = genotypes2stranded(genotypes)
            yield posinfo + ref + forward, "-"
            yield posinfo + ref + reverse, "+"
        else:
            yield posinfo + genotypes, "."
                
def parse_mpileup(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq,
                  mpileup_opts, verbose, bothStrands=0, alphabet='ACGT', region=''):
    """Run mpileup subprocess and parse output."""
    #open subprocess
    args = ['samtools', 'mpileup']
    if region:
        args += ['-r', str(region)]
    if not dna:
        args += ["-f", fasta]
    args += mpileup_opts.split() + dna + rna 
    if verbose:
        sys.stderr.write(" %s\n" % " ".join(args))
    proc = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)#, bufsize=10)
    # process lines 
    for lineTuple, strand in stranded_parser(proc.stdout, dna, stranded, minDepth):
        #get coordinate
        contig, pos, baseRef = lineTuple[:3]
        # DNA bam files
        if dna:
            refData = lineTuple[3:3+3*len(dna)]
            samplesData = lineTuple[3+3*len(dna):]
            refCov, refAlgs, refQuals = concatenate_mpileup(refData)
            #if refCov < minDepth:
            #    continue
            baseRef, refFreq = get_major_alleles(refCov, refAlgs, minDNAfreq, alphabet, bothStrands)
            if not baseRef:
                continue
            # mean qual
            gmeanQ = get_meanQ(refQuals)
        # use reference fasta
        else:
            baseRef, refFreq, refCov, gmeanQ = baseRef, set([1.0]), 100, 40.0
            baseRef = baseRef.upper()
            if baseRef not in "ACGT":
                continue
            samplesData = lineTuple[3:]
            
        cov, alg, quals = concatenate_mpileup(samplesData) 
        cov = int(cov)
        if cov<minDepth:
            continue
        # check for SNP
        bases, freqs = get_major_alleles(cov, alg, minRNAfreq, alphabet, bothStrands)
        if not bases or bases==baseRef:
            continue
        # remove ref base from alternative bases
        refBase = baseRef[0]
        if refBase in bases:
            idx = bases.index(refBase)
            freqs = freqs[:idx] + freqs[idx+1:]
            bases.remove(refBase)
        #print refCov, refAlgs, refQuals, refData
        
        # rescue major alt haplotype if the other is only very low freq
        
        #print cov, alg, quals, samplesData
        if len(baseRef) != 1 or len(bases) != 1:
            info = "[WARNING] Wrong number of bases: %s:%s %s %s\n"
            sys.stderr.write(info%(contig, pos, ",".join(baseRef), ",".join(bases)))
            print lineTuple#; sys.exit(1)
            continue
        # skip if the same base
        #if not bases.difference(baseRef):
        #    continue
        meanQ = get_meanQ(quals)
        yield (contig, pos, strand, refBase, bases.pop(), refCov, gmeanQ, refFreq.pop(), \
               cov, meanQ, freqs.pop())

def init_args(*args):
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mpileup_opts, verbose
    dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mpileup_opts, verbose = args
    
def worker(args):
    """Count overlapping intervals with given read alignment.
    The algorithm support spliced alignments. """
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mpileup_opts, verbose
    region = args
    totdata = []
    for data in parse_mpileup(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq,
                              mpileup_opts, verbose, bothStrands=0, alphabet='ACGT', region=region):
        totdata.append(data)
    return totdata

def get_regions(bam, step=int(1e6)):
    """Return chromosome regions from BAM file stepping by step"""
    regions = []
    cmd = "samtools view -H %s"%bam
    for l in commands.getoutput(cmd).split('\n'):
        # @SQ     SN:1    LN:58871917
        if not l.startswith('@SQ'):
            continue
        ldata = l.split('\t')
        slen = int(ldata[2].split(':')[1])
        chrom = ":".join(ldata[1].split(':')[1:])
        for s in xrange(1, slen+1, step):
            e = s + step - 1
            if e>slen:
                e = slen
            region = "%s:%s-%s"%(chrom, s, e)
            regions.append(region)
    return regions

def get_consecutive(data, stepsize=1):
    """Return consecutive windows allowing given max. step size"""
    return np.split(data, np.where(np.diff(data) > stepsize)[0]+1)
            
def get_covered_regions(bams, mincov=3, mapq=10, stranded=0, maxdist=16000, minsize=0):
    """Return chromosome regions covered by at least mincov reads cumulatively from all bam files.
    Regions distant less by maxdist will be collapsed.
    This is slower than parsing whole .bam, at least for ChIP-seq vs RNA-seq
    """
    import pysam
    regions = []
    sam = pysam.Samfile(bams[0])
    references, lengths = sam.references, sam.lengths
    for ref, length in zip(references, lengths):
        # store coverage
        coverage = np.zeros(length, dtype='uint16')
        for bam in bams:
            sam = pysam.Samfile(bam)
            for a in sam.fetch(reference=ref):
                # qc
                if a.mapq<mapq or a.is_duplicate or a.is_secondary or a.is_qcfail or a.is_supplementary\
                   or stranded and a.is_read2:
                    continue
                # add alg blocks
                for s, e in a.blocks:
                    coverage[s:e] += 1
        # get regions with coverage
        covered = np.where(coverage>=mincov)[0]
        for positions in get_consecutive(covered, maxdist):
            s, e = positions[0]+1, positions[-1]
            if minsize and e-s<minsize:
                continue
            region = "%s:%s-%s"%(ref, s, e)
            regions.append(region)
            return regions
            
def is_valid_file(parser, arg):
    """Return """
    if os.path.exists(arg):
        parser.error("The output file %s exists!" % arg)
    else:
        return open(arg, 'w')
            
def main():
    import argparse
    usage  = "%(prog)s [options]" 
    parser  = argparse.ArgumentParser(usage=usage, description=desc, epilog=epilog, \
                                      formatter_class=argparse.RawTextHelpFormatter)

    parser.add_argument("-v", "--verbose", default=False, action="store_true", help="verbose")    
    parser.add_argument('--version', action='version', version='1.14b')
    parser.add_argument("-o", "--output",    default=sys.stdout, #type=argparse.FileType('w'),
                        type=lambda x: is_valid_file(parser, x), 
                        help="output stream   [stdout]")
    parser.add_argument("-r", "--rna", nargs="+", 
                        help="input RNA-Seq BAM file(s)")
    refpar = parser.add_mutually_exclusive_group(required=True)
    refpar.add_argument("-d", "--dna", nargs="*", default = [], 
                        help="input DNA-Seq BAM file(s)")
    refpar.add_argument("-f", "--fasta", default = None, 
                        help="reference FASTA file")
    parser.add_argument("-s", "--stranded", default=False, action="store_true",
                        help="stranded RNAseq libraries")    
    parser.add_argument("--minDepth", default=5,  type=int,
                        help="minimal depth of coverage [%(default)s]")
    parser.add_argument("--minAltReads", default=3,  type=int,
                        help="minimum no. of reads with alternative base to call RNA editing [%(default)s]")
    parser.add_argument("--minRNAfreq",  default=0.01, type=float,
                        help="min frequency for RNA editing base [%(default)s]")
    parser.add_argument("--minDNAfreq",  default=0.99, type=float,
                        help="min frequency for genomic base [%(default)s]")
    parser.add_argument("--mpileup_opts",   default="-I -q 15 -Q 20",  ### update
                        help="options passed to mpileup         [%(default)s]")
    parser.add_argument("-t", "--threads", default=1,  type=int, 
                        help="number of cores to use [%(default)s]")
  
    # print help if no parameters
    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(1)
    o = parser.parse_args()
    if o.verbose:
        sys.stderr.write("Options: %s\n"%str(o))

    # focus only on first read in pair
    # this is valid for Illumina - in order to add support for another libs you will need to recognise them!
    if o.stranded:
        o.mpileup_opts += " --rf 64"

    header = "#chr\tpos\tstrand\tref\talt\tref cov\tref Q\tref freq\talt cov\talt Q\talt freq\n"
    o.output.write(header); o.output.flush()

    # make sure all bam files are indexed
    if o.verbose:
        sys.stderr.write("Indexing bam file(s)...\n")        
    for fn in o.dna + o.rna:
        if not os.path.isfile(fn+".bai"):
            cmd = "samtools index %s"%fn
            if o.verbose:
                sys.stderr.write(" %s\n"%cmd)
            os.system(cmd)
                
    # get regions
    #regions = get_regions(o.rna[0]) 
    if o.verbose:
        sys.stderr.write("Generating regions...\n")
    regions = get_covered_regions(o.rna, o.minDepth, 15, o.stranded); print regions

    if o.verbose:
        sys.stderr.write("Running samtools mpileup...\n")
    
    #parse pileup in single-thread mode 
    info = "%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n"
    '''
        parser = parse_mpileup(o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, \
                               o.mpileup_opts, o.verbose)
        for data in parser:
            o.output.write(info%data)
    #'''

    # process by chromosome
    initargs = (o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, o.mpileup_opts, o.verbose)
    p = Pool(o.threads, initializer=init_args, initargs=initargs)
    parser = p.imap(worker, regions)
    for data in parser:
        o.output.write("".join(info%d for d in data))

    # mark file is finished
    o.output.write("#Finished!\n"); o.output.flush()
    
if __name__=='__main__': 
    t0 = datetime.now()
    try:
        main()
    except KeyboardInterrupt:
        sys.stderr.write("\nCtrl-C pressed!      \n")
    except IOError as e:
        sys.stderr.write("I/O error({0}): {1}\n".format(e.errno, e.strerror))
    dt = datetime.now()-t0
    sys.stderr.write("#Time elapsed: %s\n" % dt)
