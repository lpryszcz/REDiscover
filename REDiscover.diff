#!/usr/bin/env python
desc="""Identify differential RNA editing sites from multiple RNAseq experiments (.bam).

TBA:
- cap at some max coverage ie. 800X
- skip reads with >25% bases soft-clipped
 - skip regions when there are so many reads soft-clipped
- maybe instead of processing individual reads, I could preload all reads from the region
and parse through them yielding one base at a time?
- skip alt alleles coming from one strand only
 - tricky to implement, as in the case of SE stranded, there won't be antisense reads at all
- skip regions around indels?
- process ref bam in the same filtering run
- add post-filtering:
 - skip regions having ie. 2+ types of changes withing 10-20bp
"""
epilog="""Author:
l.p.pryszcz@gmail.com

Warsaw/Bratislava/Fribourg, 21/07/2015
"""

import os, sys, pysam, resource, zlib
from datetime import datetime
from multiprocessing import Pool
import numpy as np

from REDiscover import logger, base2index, alphabet, fasta2calls, get_blocks, is_antisense, is_qcfail, is_duplicate
import bam2strandness

def bam2calls(bam, stranded, ref, start, end, mapq=15, baseq=20, offset=33, sfrac=0.1, window=10):
    """Return 3D array of basecalls from BAM file, as follows:
    - 1D positions from start to end of the ref
    - 2D sense and antisense strand
    - 3D base counts for ACGT
    """
    sam = pysam.AlignmentFile(bam)
    # ACGT x2 for each strand
    strandsNo = 4
    basesize = strandsNo*len(alphabet)
    n =  basesize * (end-start+1)
    calls = np.zeros(n, dtype="int64")
    # softclipped (4) & indels (1,2)
    noise = {4: np.zeros(end-start+1, dtype="uint16"), 1: np.zeros(end-start+1, dtype="uint16")}
    noise[2] = noise[1]
    # stop if ref not in sam file
    if ref not in sam.references:
        if ref.startswith('chr') and ref[3:] in sam.references:
            ref = ref[3:]
        elif 'chr%s'%ref in sam.references:
            ref = 'chr%s'%ref
        else:
            return calls.reshape((end-start+1, strandsNo, len(alphabet)))
    pa = None  
    for a in sam.fetch(ref, start, end):
        if is_qcfail(a, mapq) or is_duplicate(a, pa):
            continue
        pa = a
        # get transcript strand
        i = 0 # for +/for i == 0; for -/rev i==len(alphabet)+1
        if stranded=="firststrand":
            if not is_antisense(a):
                i = len(alphabet)
        # unstranded or secondstrand
        elif is_antisense(a):
            i = len(alphabet)
        for refi, block, bases in get_blocks(a, start, end, baseq, i, basesize):
            # softclip
            if block in (1, 2, 4):
                s = refi-start
                noise[block][s:s+bases] += 1
            elif block:
                s, e = basesize*(refi-start), basesize*(refi-start)+len(block)
                calls[s:e] += block
                
    # zero positions where there too many soft-clipped positions
    # or huge coverage difference ie. indels, intron-exon boundary
    calls = calls.reshape((end-start+1, strandsNo, len(alphabet)))
    #print bam, noise[4]; print noise[1]#; print calls[:,:2].sum(axis=2)
    for pos, (softclipped, indels) in enumerate(zip(noise[4], noise[1])):
        for strand in (0, 1):
            s = pos-window if pos>window else 0
            e = s+2*window # ignoring last bases this way
            if calls[pos][strand].sum() < calls[s:e, strand].sum(axis=1).mean()*sfrac:
                calls[pos][strand] = 0
        #if s: print ref, pos+start, s, calls[pos]
        if calls[pos][:2].sum() * sfrac < softclipped:
            calls[pos][:2] = 0
        #if s: print ref, pos+start, s, calls[pos]
        if calls[pos][:2].sum() * sfrac < indels:
            calls[pos][:2] = 0
    return calls

def get_combined_calls(bams, ref, start, end, mapq, baseq, stranded=0):
    """Combine basecalls from several files""" 
    parsers = (bam2calls(bam, stranded, ref, start, end, mapq, baseq) for bam in bams) 
    for call in np.sum(parsers, axis=0):
        if stranded:
            yield (call[0], call[1])
        else:
            yield call[0] + call[1]
    
def diff_editing(position, fasta, dna, bams, minDepth, minDNAfreq, minAltfreq, stranded, mapq, baseq, maxStrandBias, verbose):
    """Return RNA editing positions"""
    # define strands
    if not stranded[0]:
        strands = "."  
    else:
        strands = "+-"
    # 
    info = []
    z = zlib.compressobj(-1, zlib.DEFLATED, zlib.MAX_WBITS | 16)
    posinfo = "%s\t%s\t%s>%s%s"
    ref, start, end = position
    if dna:
        refparser = get_combined_calls(dna, ref, start, end, mapq, baseq, stranded=0)
    else:
        refparser = fasta2calls(fasta, ref, start, end)
    parsers = [bam2calls(bam, _stranded, ref, start, end, mapq, baseq) for bam, _stranded in zip(bams, stranded)]
    for pos, calls in enumerate(zip(refparser, *parsers), start+1):
        refcall, bamcalls = calls[0], np.array(calls[1:])
        # low dna coverage ie. N
        refcov = sum(refcall)
        if refcov < minDepth:
            continue
        refi = np.argmax(refcall)
        reffreq = 1.*refcall[refi]/refcov
        if reffreq < minDNAfreq:
            continue
        refbase = alphabet[refi]
        # collapse both strands for unstranded data, without changing dimensions
        if not stranded[0]:
            bamcalls[:, 0] += bamcalls[:, 1]
            bamcalls[:, 2] += bamcalls[:, 3]
        # process strands
        for si, strand in enumerate(strands):
            # skip if low coverage in all samples
            coverage = bamcalls[:, si].sum(axis=1)
            if coverage.max() < minDepth:
                continue
            # ignore alleles with less than 3 reads
            #bamcalls[:, si][bamcalls[:,si]<3] = 0
            # ignore alleles with huge strand enrichment if paired-end or not stranded 
            if maxStrandBias: 
                strandBias = 1.*bamcalls[:, si+2]/bamcalls[:, si]
                bamcalls[:, si][np.any((strandBias>1-maxStrandBias, strandBias<maxStrandBias), axis=0)] = 0
            # process alt bases
            for bi, base in enumerate(alphabet):
                # skip reference and if less than 3 reads per allele
                if bi==refi or bamcalls[:, si, bi].max()<3:
                    continue
                # store if freq of at least one larger than minfreq
                freqs = 1.* bamcalls[:, si, bi] / coverage
                if np.nanmax(freqs) >= minAltfreq:
                    text = z.compress(posinfo%(ref, pos, refbase, alphabet[bi], strand) + "".join("\t%s\t%.3f"%d for d in zip(coverage, freqs)) + "\n")
                    if text:
                         info.append(text)
    info.append(z.flush())
    logger(" %s:%s-%s"%position)                     
    return "".join(info)
    
def init_args(*args):
    global fasta, dna, bams, minDepth, minDNAfreq, minAltfreq, stranded, mapq, baseq, maxStrandBias, verbose
    fasta, dna, bams, minDepth, minDNAfreq, minAltfreq, stranded, mapq, baseq, maxStrandBias, verbose = args
    
def worker(position):
    # ignore all warnings
    np.seterr(all='ignore')        
    global fasta, dna, bams, minDepth, minDNAfreq, minAltfreq, stranded, mapq, baseq, maxStrandBias, verbose
    return diff_editing(position, fasta, dna, bams, minDepth, minDNAfreq, minAltfreq, stranded, mapq, baseq, maxStrandBias, verbose)
    
def get_consecutive(data, stepsize=1):
    """Return consecutive windows allowing given max. step size"""
    return np.split(data, np.where(np.diff(data) > stepsize)[0]+1)

def worker_coverage(args):
    """return coverage"""
    bam, ref, mapq = args
    sam = pysam.Samfile(bam)
    ref2len = {r: l for r, l in zip(sam.references, sam.lengths)}
    coverage = np.zeros(ref2len[ref], dtype='uint16')
    for a in sam.fetch(reference=ref):
        if is_qcfail(a, mapq): continue
        for s, e in a.blocks:
            coverage[s:e] += 1
    return coverage

def get_covered_regions_per_bam(bams, mincov=3, mapq=15, threads=4, chrs=[], verbose=0,  maxdist=16000, step=100000):
    """Return chromosome regions covered by at least mincov."""
    p = Pool(threads)
    sam = pysam.Samfile(bams[0])
    references, lengths = sam.references, sam.lengths
    for ref, length in zip(references, lengths):
        if chrs and ref not in chrs:
            if verbose:
                sys.stderr.write(" skipped %s\n"%ref)
            continue
        coverage = np.zeros(length, dtype='uint16')
        for _coverage in p.imap_unordered(worker_coverage, [(bam, ref, mapq) for bam in bams]):
            coverage = np.max([coverage, _coverage], axis=0)
        # get regions with coverage
        covered = np.where(coverage>=mincov)[0]
        for positions in get_consecutive(covered, maxdist):
            if len(positions)<1:
                continue
            s, e = positions[0]+1, positions[-1]+1
            # further split regions for max 1M windows
            while s < e-step:
                yield ref, s, s+step
                s += step
            yield ref, s, e
    
def load_bed(fname):
    """Return regions from BED file"""
    if os.path.isfile(fname):
        for l in open(fname):
            if l.startswith('#') or not l[:-1]:
                continue
            ldata = l[:-1].replace(',','').split('\t')
            if len(ldata) == 3:
                ref, start, end = ldata
            else:
                ref, se = ldata[0].split(':')
                start, end = se.split('-')
            start, end = map(int, (start, end))
            yield ref, start, end
    else:
        ref, se = fname.replace(',','').split('\t')[0].split(':')
        start, end = se.split('-')
        start, end = map(int, (start, end))
        yield ref, start, end
            
def get_differential_editing(outfn, regionsfn, fasta, dna, rna, minDepth, minDNAfreq, minAltfreq,
                             stranded, mapq, bcq, threads, maxStrandBias, verbose, chrs):
    """Get alternative base coverage and frequency for every bam file"""
    out = open(outfn, "w")
    header = "## %s\n"%" ".join(sys.argv)
    header += "## %s\n" % "\t".join(rna)
    header += "## %s\n" % "\t".join(stranded)
    header += "#chr\tpos\tvariation\t%s\n"%"\t".join("%s cov\t%s alt freq"%(fn, fn) for fn in rna)
    # http://stackoverflow.com/a/22311297/632242
    z = zlib.compressobj(-1, zlib.DEFLATED, zlib.MAX_WBITS | 16)
    header = z.compress(header) + z.flush()
    out.write(header)

    logger("Genotyping...")
    if regionsfn:
        regions = load_bed(regionsfn)
    else:
        regions = get_covered_regions_per_bam(rna, minDepth, mapq, threads, chrs, verbose) 

    i = 0
    if threads<2: # this is useful for debugging
        for i, region in enumerate(regions, 1):
            parser = diff_editing(region, fasta, dna, rna, minDepth, minDNAfreq, minAltfreq,
                                  stranded, mapq, bcq, maxStrandBias, verbose)
            for data in parser:
                out.write(data)
    else:
        initargs = (fasta, dna, rna, minDepth, minDNAfreq, minAltfreq, stranded, mapq, bcq, maxStrandBias, verbose)
        p = Pool(threads, initializer=init_args, initargs=initargs)#, maxtasksperchild=20)
        parser = p.imap(worker, regions) #_unordered , chunksize=10
        for i, data in enumerate(parser, 1):
            out.write(data)
            
    logger("%s regions processed"%i)
    out.close()

def compute_strandness(rna, gtf, mapq, threads, verbose, subset=0.01, limit=0.66):
    """Compute strandness"""
    strands = []
    skipUnstranded = False
    toSkip = set()
    for bam, reads, strandness in bam2strandness.process_bams(rna, gtf, mapq, subset, threads, verbose):
        strand = ""
        if strandness>=limit:
            strand = "secondstrand"
        elif 1.-strandness>=limit:
            strand = "firststrand"
        strands.append(strand)
        if strand and .05<strandness<0.95:
            sys.stderr.write(" [WARNING] %s poorly stranded: %.3f\n"%(bam, strandness))
        if not reads:
            sys.stderr.write(" [WARNING] %s without alignments!\n"%(bam, ))
            toSkip.add(bam)
            
    # notify about mixed strandness
    strandtypes = set(strands)
    if len(strandtypes)>1 and "" in strandtypes:
        sys.stderr.write("[WARNING] Mixing stranded and unstranded BAM files is not allowed: %s!\n"%str(strandtypes))
        skipUnstranded = True
        
    if skipUnstranded or toSkip:
        _rna, _strands = [], []
        for fn, strand in zip(rna, strands):
            if skipUnstranded and not strand or fn in toSkip:
                sys.stderr.write(" %s skipped!\n"%fn)
                continue
            _rna.append(fn)
            _strands.append(strand)
        rna, strands = _rna, _strands
        
    return strands, rna

def is_any_lib_single(bams):
    """Return True if any lib is single-end"""
    for bam in bams:
        r = pysam.Samfile(bam).next()
        if not r.is_paired:
            return True
    
def main():
    import argparse
    usage  = "%(prog)s [options]" 
    parser  = argparse.ArgumentParser(usage=usage, description=desc, epilog=epilog, \
                                      formatter_class=argparse.RawTextHelpFormatter)
    
    parser.add_argument("-v", "--verbose", default=False, action="store_true", help="verbose")    
    parser.add_argument('--version', action='version', version='1.15b')
    parser.add_argument("-o", "--out", required=1, help="output file")
    parser.add_argument("-b", "--regions", "--bed", help="BED file with regions to genotype")
    parser.add_argument("-c", "--chrs", nargs="*", default=[], help="analyse only some chromosomes [all]")
    refpar = parser.add_mutually_exclusive_group(required=True)
    refpar.add_argument("-d", "--dna", nargs="*", default = [], help="input DNA-Seq BAM file(s)")
    refpar.add_argument("-f", "--fasta", default='', help="reference FASTA file")
    parser.add_argument("-r", "--rna", nargs="+", help="input RNA-Seq BAM file(s)")
    strand = parser.add_mutually_exclusive_group()
    parser.add_argument("-g", "--gtf", default="", help="auto dectection of strandness [unstranded]")
    parser.add_argument("-s", "--stranded", "-fr-secondstrand", action="store_true", 
                        help="stranded RNAseq libraries ie. Illumina or Standard Solid")
    parser.add_argument("-fr-firststrand", default=False, action="store_true", 
                        help="stranded RNAseq libraries ie. dUTP, NSR, NNSR")
    parser.add_argument("--minDepth", default=5,  type=int,
                        help="minimal depth of coverage [%(default)s]")
    parser.add_argument("--minDNAfreq",  default=0.99, type=float,
                        help="min frequency for DNA base [%(default)s]")
    parser.add_argument("--minAltfreq",  default=0.01, type=float,
                        help="min frequency for RNA editing base [%(default)s]")
    parser.add_argument("-q", "--mapq", default=3, type=int, help="mapping quality [%(default)s]")
    parser.add_argument("-Q", "--bcq", default=20, type=int, help="basecall quality [%(default)s]")
    parser.add_argument("-m", "--maxStrandBias", default=0.1, type=float, help="max allowed strand bias [%(default)s]")
    parser.add_argument("-t", "--threads", default=4, type=int, help="number of cores to use [%(default)s]")
    
    # print help if no parameters
    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(1)
    o = parser.parse_args()
    if o.verbose:
        sys.stderr.write("Options: %s\n"%str(o))
     
    # calculate differential editing if file doesn't exist
    if not o.out.endswith('.gz'): o.out += ".gz"
    if os.path.isfile(o.out) and open(o.out).readline():
        sys.stderr.write("Outfile exists or not empty: %s\n"%o.out)
        sys.exit(1)
        
    # check if all input files exists
    for fn in o.dna+o.rna+[o.fasta]:
        if fn and not os.path.isfile(fn):
            sys.stderr.write("No such file: %s\n"%fn)
            sys.exit(1)

    logger("Indexing bam file(s)...")
    for fn in o.dna+o.rna:
        if not os.path.isfile(fn+".bai"):
            cmd = "samtools index %s"%fn
            if verbose:
                sys.stderr.write(" %s\n"%cmd)
            os.system(cmd)

    # mark stranded protocol
    if o.gtf:
        logger("Detecting strandness in BAMs...")
        o.stranded, o.rna = compute_strandness(o.rna, o.gtf, o.mapq, o.threads, o.verbose)
    elif o.stranded:
        o.stranded = ["secondstrand"]*len(o.rna)
    elif o.fr_firststrand:
        o.stranded = ["firststrand"]*len(o.rna)
    else:
        o.stranded = [""]*len(o.rna)

    # disable strandBias filter if stranded and single-end
    if o.stranded[0] and is_any_lib_single(o.rna): 
        logger("[WARNING] Stranded and single-end libraries present: disabled maxStrandBias!", 0)
        o.maxStrandBias = 0
                    
    get_differential_editing(o.out, o.regions, o.fasta, o.dna, o.rna, o.minDepth, o.minDNAfreq, o.minAltfreq,
                             o.stranded, o.mapq, o.bcq, o.threads, o.maxStrandBias, o.verbose, o.chrs)
        
if __name__=='__main__': 
    t0 = datetime.now()
    try:
        main()
    except KeyboardInterrupt:
        sys.stderr.write("\nCtrl-C pressed!      \n")
    dt = datetime.now()-t0
    sys.stderr.write("#Time elapsed: %s\n" % dt)
