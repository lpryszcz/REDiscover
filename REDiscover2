#!/usr/bin/env python
desc="""Identify RNA editing sites from RNAseq and DNAseq alignements (.bam).

-s / --stranded optimised for Illumina type stranded protocols

TBD:
- rescue major alt haplotype if the other is only very low freq!!
- use read1/2 in --stranded, so far only using read1
- on indels removal from read, make sure to strip quals properly!
"""
epilog="""Author:
l.p.pryszcz@gmail.com

Warsaw/Bratislava/Fribourg, 21/07/2015
"""

import os, sys, pysam, resource
from datetime import datetime
from multiprocessing import Pool
import numpy as np

def get_major_alleles(cov, alts, minFreq, alphabet="ACGT", minCount=3):
    """Return major alleles that passed filtering and their frequencies."""
    bases, freqs = [], []
    for base_count, base in zip((alts.count(b) for b in alphabet), alphabet):
        # skip if alt base calling if less than 3 reads
        if base_count < minCount:
            continue
        freq = base_count*1.0/cov
        #check freq
        if freq < minFreq:
            continue
        bases.append(base)
        freqs.append(freq)
    return bases, freqs

def get_meanQ(quals, offset=33):
    """Return mean quality"""
    return np.mean([ord(q)-offset for q in quals])

def _unload_region(region):
    """Return start position"""
    start = end = None
    ref = region.split(':')[0]
    if len(region.split(':'))==2:
        start_end = region.split(':')[1].split('-')
        start = int(start_end[0])
        if len(start_end)==2:
            end = int(start_end[1])
    return ref, start, end
    
def bam2calls(bam, region="", mapq=15, baseq=20, offset=33):
    """Return list of basecalls from BAM file. Each list element is as follows:
    - genomic position (zero-based)
    - list of + strand basecalls
    - list of + strand quals
    - list of - strand basecalls
    - list of - strand quals
    """
    calls = []
    # process reads
    sam = pysam.Samfile(bam)
    ref, start, end = _unload_region(region)
    for a in sam.fetch(region=region):
        if start and a.pos<start-1 or end and a.pos>end-1 \
           or a.mapq<mapq or a.is_duplicate or a.is_secondary or a.is_qcfail or a.is_supplementary:
            continue
        # add containers for new positions 
        s = a.pos
        if calls and s < calls[-1][0]:
            s = calls[-1][0]
        # pos forward bases quals, reverse bases & quals
        calls += [[i, [], [], [], []] for i in range(s, a.aend)]
        # report previous calls
        while calls[0] < a.pos:
            yield calls.pop(0)
        # add calls from current read
        for b, q, (readi, refi) in zip(a.seq, a.qual, a.aligned_pairs):
            # skip indels and low base calls
            if not refi or ord(q)-offset<baseq:
                continue
            index = refi - a.pos
            # for +/for i == 1; for -/rev i==3
            i = 1
            if a.is_read1 and a.is_reverse or a.is_read2 and not a.is_reverse:
                i = 3
            # store basecall and quality
            calls[index][i].append(b)
            calls[index][i+1].append(q)    
    # report remaining calls
    while calls:
        yield calls.pop(0)

def fasta2calls(fastafn, region="", cov=100, qual="I"):
    """Return list of basecalls from FastA file."""
    ref, start, end = _unload_region(region)
    fasta = pysam.Fastafile(fastafn)
    for refi, b in enumerate(fasta.fetch(region=region), start-1):
        yield refi, [(".", b*cov, get_meanQ(qual*cov))]

def get_combined_calls(bams, region, mapq, baseq, stranded=0):
    """Combine basecalls from several files"""
    parsers = [bam2calls(bam, region, mapq, baseq) for bam in bams]
    calls = [next(p, None) for p in parsers]
    while True:
        # get positions
        positions = [call[0] for call in calls if call]
        if not positions:
            break
        curpos = min(positions)
        curcalls = filter(lambda call: call and call[0]==curpos, calls)
        # unload calls
        fbases, fquals, rbases, rquals = [], [], [], []
        for _pos, _fbases, _fquals, _rbases, _rquals in curcalls:
            fbases += _fbases
            fquals += _fquals
            rbases += _rbases
            rquals += _rquals
        # report only if any bases
        if len(fbases+rbases):
            #print curpos, fbases[:5], get_meanQ(fquals), rbases[:5], get_meanQ(rquals)
            if stranded:
                # this is true for Illumina stranded protocol
                data = [("-", fbases, get_meanQ(fquals)), ("+", rbases, get_meanQ(rquals))]
            else:
                data = [(".", fbases+rbases, get_meanQ(fquals+rquals))]
            yield curpos, data
        # load next entry only for processed parsers
        for i in range(len(parsers)):
            if calls[i] and calls[i][0]==curpos:
                calls[i] = next(parsers[i], None)
        
def get_calls(dna, rna, fasta, stranded, region, mapq, baseq):
    """Return basecalls from multiple BAM (& FastA) file(s)"""
    ref, start, end = _unload_region(region)
    
    if not dna:
        refparser = fasta2calls(fasta, region)
    else:
        refparser = get_combined_calls(dna, region, mapq, baseq, stranded=0)

    # define parsers
    parsers = [refparser, get_combined_calls(rna, region, mapq, baseq, stranded)]
    calls = [next(p, None) for p in parsers]
    while True:
        # get positions
        positions = [call[0] for call in calls if call]
        if not positions:
            break
        curpos = min(positions)
        curcalls = filter(lambda call: call and call[0]==curpos, calls)
        if len(curcalls)==2:
            refstrand, refbases, refQ = curcalls[0][1][0]
            for strand, bases, meanQ in curcalls[1][1]:
                yield ref, curpos, strand, refbases, refQ, bases, meanQ
        # load next entry only for processed parsers
        for i in range(len(parsers)):
            if calls[i] and calls[i][0]==curpos:
                calls[i] = next(parsers[i], None)

def region2editing(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq,
                   mapq, baseq, verbose=0, region=''):
    """Return RNA editing positions"""
    parser = get_calls(dna, rna, fasta, stranded, region, mapq, baseq)
    for contig, pos, strand, refsases, gmeanQ, bases, meanQ in parser:
        refCov = len(refsases)
        if refCov<minDepth:
            continue
        baseRef, refFreq = get_major_alleles(refCov, refsases, minDNAfreq)
        if not baseRef:
            continue

        cov = len(bases)
        if cov<minDepth:
            continue
            
        # check for SNP
        bases, freqs = get_major_alleles(cov, bases, minRNAfreq)
        if not bases or bases==baseRef:
            continue
        #print baseRef, refFreq, bases, freqs
        # remove ref base from alternative bases
        refBase = baseRef[0]
        if refBase in bases:
            idx = bases.index(refBase)
            freqs = freqs[:idx] + freqs[idx+1:]
            bases.remove(refBase)
        
        # rescue major alt haplotype if the other is only very low freq
        
        if len(baseRef) != 1 or len(bases) != 1:
            info = "[WARNING] Wrong number of bases: %s:%s %s %s\n"
            sys.stderr.write(info%(contig, pos, ",".join(baseRef), ",".join(bases)))
            continue
        # skip if the same base
        #if not bases.difference(baseRef):
        #    continue
        yield (contig, pos, strand, refBase, bases.pop(), refCov, gmeanQ, refFreq[0], \
               cov, meanQ, freqs[0])

def init_args(*args):
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mapq, bcq, verbose
    dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mapq, bcq, verbose = args
    
def worker(args):
    """Count overlapping intervals with given read alignment.
    The algorithm support spliced alignments. """
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mapq, bcq, verbose
    region = args
    totdata = []
    for data in region2editing(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq,
                               mapq, bcq, verbose, region=region):
        totdata.append(data)
    return totdata

def get_regions(bam, step=int(1e5)):
    """Return chromosome regions from BAM file stepping by step"""
    sam = pysam.Samfile(bam)
    for ref, length in zip(sam.references, sam.lengths):
        for s in xrange(1, length+1, step):
            e = s + step - 1
            if e>length:
                e = length
            region = "%s:%s-%s"%(ref, s, e)
            yield region
    
def get_consecutive(data, stepsize=1):
    """Return consecutive windows allowing given max. step size"""
    return np.split(data, np.where(np.diff(data) > stepsize)[0]+1)
            
def get_covered_regions(bams, mincov=3, mapq=10, stranded=0, maxdist=16000, minsize=0):
    """Return chromosome regions covered by at least mincov reads cumulatively from all bam files.
    
    Regions distant less by maxdist will be collapsed. Make sure, maxdist is large enough,
    ie 16kb is typical linear index block size for sorted bam. 
    """
    sam = pysam.Samfile(bams[0])
    references, lengths = sam.references, sam.lengths
    for ref, length in zip(references, lengths):
        #if ref!="7": continue
        # store coverage
        coverage = np.zeros(length, dtype='uint16')
        for bam in bams:
            sam = pysam.Samfile(bam)
            for a in sam.fetch(reference=ref):
                # qc and skip read2 if stranded
                if a.mapq<mapq or a.is_duplicate or a.is_secondary or a.is_qcfail or a.is_supplementary \
                   or stranded and a.is_read2:
                    continue
                # add alg blocks
                for s, e in a.blocks:
                    coverage[s:e] += 1
        # get regions with coverage
        covered = np.where(coverage>=mincov)[0]
        for positions in get_consecutive(covered, maxdist):
            if len(positions)<1:
                continue
            s, e = positions[0]+1, positions[-1]+1
            if minsize and e-s<minsize:
                continue
            region = "%s:%s-%s"%(ref, s, e)
            yield region

def logger(info, add_timestamp=1, add_memory=1, out=sys.stderr):
    """Report nicely formatted stream to stderr"""
    memory = timestamp = ""
    if add_timestamp:
        timestamp = "[%s] "%datetime.ctime(datetime.now())
    if add_memory:
        memory = "[memory: %6i Mb]"%(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024, )
    out.write("%s%s%s\n"%(timestamp, info, memory))

def main():
    import argparse
    usage  = "%(prog)s [options]" 
    parser  = argparse.ArgumentParser(usage=usage, description=desc, epilog=epilog, \
                                      formatter_class=argparse.RawTextHelpFormatter)
    
    parser.add_argument("-v", "--verbose", default=False, action="store_true", help="verbose")    
    parser.add_argument('--version', action='version', version='1.15a')
    parser.add_argument("-o", "--output", required=True,  help="output file")
    parser.add_argument("-r", "--rna", nargs="+", 
                        help="input RNA-Seq BAM file(s)")
    refpar = parser.add_mutually_exclusive_group(required=True)
    refpar.add_argument("-d", "--dna", nargs="*", default = [], 
                        help="input DNA-Seq BAM file(s)")
    refpar.add_argument("-f", "--fasta", default = None, 
                        help="reference FASTA file")
    parser.add_argument("-s", "--stranded", default=False, action="store_true",
                        help="stranded RNAseq libraries")    
    parser.add_argument("--minDepth", default=5,  type=int,
                        help="minimal depth of coverage [%(default)s]")
    parser.add_argument("--minAltReads", default=3,  type=int,
                        help="minimum no. of reads with alternative base to call RNA editing [%(default)s]")
    parser.add_argument("--minRNAfreq",  default=0.01, type=float,
                        help="min frequency for RNA editing base [%(default)s]")
    parser.add_argument("--minDNAfreq",  default=0.99, type=float,
                        help="min frequency for genomic base [%(default)s]")
    parser.add_argument("-m", "--mapq", default=15, type=int, help="mapping quality [%(default)s]")
    parser.add_argument("--bcq", default=20, type=int, help="basecall quality [%(default)s]")
    parser.add_argument("-t", "--threads", default=4, type=int, help="number of cores to use [%(default)s]")
    
    # print help if no parameters
    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(1)
    o = parser.parse_args()
    if o.verbose:
        sys.stderr.write("Options: %s\n"%str(o))
    
    # check if all input files exists
    for fn in o.dna+o.rna:
        if not os.path.isfile(fn):
            sys.stderr.write("No such file: %s\n"%fn)
            sys.exit(1)

    # check if outfile exists and not empty
    if o.output=="-":
        output = sys.stdout
    elif os.path.exists(o.output) and open(o.output).readline():
        sys.stderr.write("The output file %s exists!\n"%o.output)
        sys.exit(1)
    else:
        output = open(o.output, "w")

    runinfo = " ".join(sys.argv)
    header = "## %s\n# chr\tpos\tstrand\tref\talt\tref cov\tref Q\tref freq\talt cov\talt Q\talt freq\n"%runinfo
    output.write(header); output.flush()
    info = "%s\t"*10 + "%s\n" 
    
    #'''
    regions = get_regions(o.rna[0])
    for region in regions:
        print region
        parser = region2editing(o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, \
                                o.mapq, o.bcq, o.verbose, region)
        for data in parser:
            output.write(info%data)
    '''
    logger("Indexing bam file(s)...")
    for fn in o.dna + o.rna:
        if not os.path.isfile(fn+".bai"):
            cmd = "samtools index %s"%fn
            if o.verbose:
                sys.stderr.write(" %s\n"%cmd)
            os.system(cmd)

    logger("Generating regions...")
    if o.dna:
        # use only covered regions if genome BAM provided
        regions = get_covered_regions(o.rna, o.minDepth, o.mapq, o.stranded)
    else:
        # don't bother and use all alignments if not ref genome BAM provided
        regions = get_regions(o.rna[0])
        
    logger("Genotyping...")
    initargs = (o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, \
                o.mapq, o.bcq, o.verbose)
    p = Pool(o.threads, initializer=init_args, initargs=initargs)
    parser = p.imap(worker, regions)
    for data in parser:
        output.write("".join(info%d for d in data))
    #'''
    output.write("#Finished!\n")
    logger("Done!")
    
if __name__=='__main__': 
    t0 = datetime.now()
    try:
        main()
    except KeyboardInterrupt:
        sys.stderr.write("\nCtrl-C pressed!      \n")
    except IOError as e:
        sys.stderr.write("I/O error({0}): {1}\n".format(e.errno, e.strerror))
    dt = datetime.now()-t0
    sys.stderr.write("#Time elapsed: %s\n" % dt)
