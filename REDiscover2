#!/usr/bin/env python
desc="""Identify RNA editing sites from RNAseq and DNAseq alignements (.bam).

-s / --stranded optimised for Illumina type stranded protocols

TBD:
- report editing for heterozygous sites
- use stranded info to distinguish between real editing and SNPs
"""
epilog="""Author:
l.p.pryszcz@gmail.com

Warsaw/Bratislava/Fribourg, 21/07/2015
"""

import os, sys, pysam, resource
from datetime import datetime
from multiprocessing import Pool
import numpy as np

alphabet = "ACGTN"
base2index = {b: i for i, b in enumerate(alphabet)}
for i, b in enumerate(alphabet.lower()):
    base2index[b] = i

def get_major_alleles(bases, freqs, maxfrac=0.33):
    """Return major alleles, this is alleles with freq
    at least minfrac of max frac for given locus"""
    if len(bases)>1:
        minfreq = maxfrac * max(freqs)
        for i, f in enumerate(freqs):
            if f < minfreq:
                bases.pop(i)
                freqs.pop(i)
    return bases, freqs
                    
def get_allele_freqs(counts, minFreq=0.03, minCount=3):
    """Return major alleles that passed filtering and their frequencies."""
    bases, freqs = [], []
    for c, b in zip(counts, alphabet):
        # skip if alt base calling if less than 3 reads
        if c < minCount:
            continue
        freq = 1.*c/sum(counts)
        #check freq
        if freq < minFreq:
            continue
        bases.append(b)
        freqs.append(freq)
    return bases, freqs

def get_meanQ(quals, offset=33):
    """Return mean quality"""
    return np.mean([ord(q)-offset for q in quals])

def _unload_region(region):
    """Return start position"""
    start = end = None
    ref = region.split(':')[0]
    if len(region.split(':'))==2:
        start_end = region.split(':')[1].split('-')
        start = int(start_end[0])
        if len(start_end)==2:
            end = int(start_end[1])
    return ref, start, end

def is_qcfail(a, mapq=15):
    """Return True if alignment record fails quality checks"""
    if a.mapq<mapq or a.is_duplicate or a.is_secondary or a.is_qcfail or a.is_supplementary:
        return True
    
def bam2calls(bam, region="", mapq=15, baseq=20, offset=33):
    """Return list of basecalls from BAM file. Each list element is as follows:
    - genomic position (zero-based)
    - list of + strand basecalls
    - list of + strand quals
    - list of - strand basecalls
    - list of - strand quals
    """
    sam = pysam.Samfile(bam)
    ref, start, end = _unload_region(region)
    # stop if ref not in sam file
    if ref not in sam.references:
        raise StopIteration
    calls = [[start-1, [0]*len(alphabet), [], [0]*len(alphabet), []]]
    for a in sam.fetch(ref, start, end):
        if start and a.pos<start-1 or end and a.pos>end-1 or is_qcfail(a, mapq): 
            continue
        # add containers for new positions 
        ## pos forward bases quals, reverse bases & quals
        calls += [[i, [0]*len(alphabet), [], [0]*len(alphabet), []] for i in xrange(calls[-1][0]+1, a.aend)]
        # report previous calls
        while calls[0][0] < a.pos:
            yield calls.pop(0)
        # add calls from current read
        for readi, refi in a.aligned_pairs:
            if not readi:
                continue
            b, q = a.seq[readi], a.qual[readi]
            # skip indels and low base calls
            if not refi or ord(q)-offset<baseq:
                continue
            index = refi - calls[0][0]
            # for +/for i == 1; for -/rev i==3
            i = 1
            if a.is_read1 and a.is_reverse or a.is_read2 and not a.is_reverse:
                i = 3
            # store basecall and quality
            calls[index][i][base2index[b]] += 1
            calls[index][i+1].append(q)    
    # report remaining calls
    for call in calls: 
        yield call

def fasta2calls(fastafn, region="", cov=100, qual="I"):
    """Return list of basecalls from FastA file."""
    ref, start, end = _unload_region(region)
    fasta = pysam.Fastafile(fastafn)
    for refi, b in enumerate(fasta.fetch(region=region), start-1):
        counts = [0]*len(alphabet)
        counts[base2index[b]] += cov 
        yield refi, [(".", counts, qual)]

def add_lists(*lists):
    """Return new list with elements being sums of elements of list1 and list2"""
    return [sum(c) for c in zip(*lists)]
        
def get_combined_calls(bams, region, mapq, baseq, stranded=0):
    """Combine basecalls from several files"""
    parsers = [bam2calls(bam, region, mapq, baseq) for bam in bams]
    calls = [next(p, None) for p in parsers]
    while True:
        # get positions
        positions = [call[0] for call in calls if call]
        if not positions:
            break
        curpos = min(positions)
        curcalls = filter(lambda call: call and call[0]==curpos, calls)
        # unload calls
        fbases, rbases = [0]*len(alphabet), [0]*len(alphabet)
        fquals, rquals = [], []
        for _pos, _fbases, _fquals, _rbases, _rquals in curcalls:
            fbases = add_lists(fbases, _fbases)
            fquals += _fquals
            rbases = add_lists(rbases, _rbases)
            rquals += _rquals
        # report only if any bases
        if len(fbases+rbases):
            if stranded:
                # this is true for Illumina stranded protocol
                data = [("-", fbases, fquals), ("+", rbases, rquals)]
            else:
                # return sum of calls from + and - strand
                data = [(".", add_lists(fbases, rbases), fquals+rquals)]
            yield curpos, data
        # load next entry only for processed parsers
        for i in range(len(parsers)):
            if calls[i] and calls[i][0]==curpos:
                calls[i] = next(parsers[i], None)
        
def get_calls(dna, rna, fasta, stranded, region, mapq, baseq):
    """Return basecalls from multiple BAM (& FastA) file(s)"""
    ref, start, end = _unload_region(region)
    
    if not dna:
        refparser = fasta2calls(fasta, region)
    else:
        refparser = get_combined_calls(dna, region, mapq, baseq, stranded=0)

    # define parsers
    parsers = [refparser, get_combined_calls(rna, region, mapq, baseq, stranded)]
    calls = [next(p, None) for p in parsers]
    while True:
        # get positions
        positions = [call[0] for call in calls if call]
        if not positions:
            break
        curpos = min(positions)
        curcalls = filter(lambda call: call and call[0]==curpos, calls)
        if len(curcalls)==2:
            refstrand, refbases, refQ = curcalls[0][1][0]
            for strand, bases, meanQ in curcalls[1][1]:
                yield ref, curpos+1, strand, refbases, refQ, bases, meanQ
        # load next entry only for processed parsers
        for i in range(len(parsers)):
            if calls[i] and calls[i][0]==curpos:
                calls[i] = next(parsers[i], None)

def region2editing(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq,
                   mapq, baseq, verbose=0, region=''):
    """Return RNA editing positions"""
    parser = get_calls(dna, rna, fasta, stranded, region, mapq, baseq)
    for contig, pos, strand, refbases, refquals, sbases, squals in parser:
        refCov, cov = sum(refbases), sum(sbases)
        #print contig, pos, strand, refbases, sbases
        if refCov<minDepth or cov<minDepth:
            continue
            
        # check for SNP
        baseRef, refFreq = get_allele_freqs(refbases, minDNAfreq)
        bases, freqs = get_allele_freqs(sbases, minRNAfreq)
        if not baseRef or not bases or bases==baseRef:
            continue

        # keep only major allele(s)
        baseRef, refFreq = get_major_alleles(baseRef, refFreq)
            
        # remove ref base from alternative bases
        refBase = baseRef[0]
        if refBase in bases:
            idx = bases.index(refBase)
            bases.pop(idx)
            freqs.pop(idx)

        # keep only major allele(s) from sample, but after removing ref allele
        bases, freqs = get_major_alleles(bases, freqs)
        
        # skip if more alternative alleles
        if len(refBase) > 1 or len(bases) > 1:
            #print contig, pos, strand, refbases, sbases, baseRef, refFreq, bases, freqs
            info = "[WARNING] Wrong number of bases: %s:%s %s %s\n"
            sys.stderr.write(info%(contig, pos, ",".join(baseRef), ",".join(bases)))
            continue
            
        yield (contig, pos, strand, refBase, bases[0], refCov, get_meanQ(refquals),
               refFreq[0], cov, get_meanQ(squals), freqs[0])

def init_args(*args):
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mapq, bcq, verbose
    dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mapq, bcq, verbose = args
    
def worker(args):
    """Count overlapping intervals with given read alignment.
    The algorithm support spliced alignments. """
    global dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq, mapq, bcq, verbose
    region = args
    totdata = []
    for data in region2editing(dna, rna, fasta, stranded, minDepth, minDNAfreq, minRNAfreq,
                               mapq, bcq, verbose, region=region):
        totdata.append(data)
    return totdata

def get_consecutive(data, stepsize=1):
    """Return consecutive windows allowing given max. step size"""
    return np.split(data, np.where(np.diff(data) > stepsize)[0]+1)
            
def get_covered_regions(bams, mincov=3, mapq=10, maxdist=16000):
    """Return chromosome regions covered by at least mincov"""
    sam = pysam.Samfile(bams[0])
    references, lengths = sam.references, sam.lengths
    for ref, length in zip(references, lengths):
        #if ref!="chr21": continue
        coverage = np.zeros(length, dtype='uint16')
        for bam in bams:
            sam = pysam.Samfile(bam)
            for a in sam.fetch(reference=ref):
                if is_qcfail(a, mapq):
                    continue
                # add alg blocks
                for s, e in a.blocks:
                    coverage[s:e] += 1
        # get regions with coverage
        covered = np.where(coverage>=mincov)[0]
        for positions in get_consecutive(covered, maxdist):
            if len(positions)<1:
                continue
            s, e = positions[0]+1, positions[-1]+1
            region = "%s:%s-%s"%(ref, s, e)
            yield region

def logger(info, add_timestamp=1, add_memory=1, out=sys.stderr):
    """Report nicely formatted stream to stderr"""
    memory = timestamp = ""
    if add_timestamp:
        timestamp = "[%s] "%datetime.ctime(datetime.now())
    if add_memory:
        memory = " [memory: %6i Mb]"%(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024, )
    out.write("%s%s%s\n"%(timestamp, info, memory))

def main():
    import argparse
    usage  = "%(prog)s [options]" 
    parser  = argparse.ArgumentParser(usage=usage, description=desc, epilog=epilog, \
                                      formatter_class=argparse.RawTextHelpFormatter)
    
    parser.add_argument("-v", "--verbose", default=False, action="store_true", help="verbose")    
    parser.add_argument('--version', action='version', version='1.15a')
    parser.add_argument("-o", "--output", required=True,  help="output file")
    parser.add_argument("-r", "--rna", nargs="+", 
                        help="input RNA-Seq BAM file(s)")
    refpar = parser.add_mutually_exclusive_group(required=True)
    refpar.add_argument("-d", "--dna", nargs="*", default = [], 
                        help="input DNA-Seq BAM file(s)")
    refpar.add_argument("-f", "--fasta", default = None, 
                        help="reference FASTA file")
    parser.add_argument("-s", "--stranded", default=False, action="store_true",
                        help="stranded RNAseq libraries")    
    parser.add_argument("--minDepth", default=5,  type=int,
                        help="minimal depth of coverage [%(default)s]")
    parser.add_argument("--minAltReads", default=3,  type=int,
                        help="minimum no. of reads with alternative base to call RNA editing [%(default)s]")
    parser.add_argument("--minRNAfreq",  default=0.01, type=float,
                        help="min frequency for RNA editing base [%(default)s]")
    parser.add_argument("--minDNAfreq",  default=0.99, type=float,
                        help="min frequency for genomic base [%(default)s]")
    parser.add_argument("-m", "--mapq", default=15, type=int, help="mapping quality [%(default)s]")
    parser.add_argument("--bcq", default=20, type=int, help="basecall quality [%(default)s]")
    parser.add_argument("-t", "--threads", default=4, type=int, help="number of cores to use [%(default)s]")
    
    # print help if no parameters
    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(1)
    o = parser.parse_args()
    if o.verbose:
        sys.stderr.write("Options: %s\n"%str(o))
    
    # check if all input files exists
    for fn in o.dna+o.rna:
        if not os.path.isfile(fn):
            sys.stderr.write("No such file: %s\n"%fn)
            sys.exit(1)

    # check if outfile exists and not empty
    if o.output=="-":
        output = sys.stdout
    elif os.path.exists(o.output) and open(o.output).readline():
        sys.stderr.write("The output file %s exists!\n"%o.output)
        sys.exit(1)
    else:
        output = open(o.output, "w")

    runinfo = " ".join(sys.argv)
    header = "## %s\n# chr\tpos\tstrand\tref\talt\tref cov\tref Q\tref freq\talt cov\talt Q\talt freq\n"%runinfo
    output.write(header); output.flush()
    info = "%s\t%s\t%s\t%s\t%s\t%s\t%.3f\t%.3f\t%s\t%.3f\t%.3f\n"
    
    logger("Indexing bam file(s)...")
    for fn in o.dna + o.rna:
        if not os.path.isfile(fn+".bai"):
            cmd = "samtools index %s"%fn
            if o.verbose:
                sys.stderr.write(" %s\n"%cmd)
            os.system(cmd)

    logger("Generating regions...")
    regions = get_covered_regions(o.rna, o.minDepth, o.mapq)        
    '''
    for region in regions:
        print region
        parser = region2editing(o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, \
                                o.mapq, o.bcq, o.verbose, region)
        for data in parser:
            output.write(info%data)    
    '''
    logger("Genotyping...")
    initargs = (o.dna, o.rna, o.fasta, o.stranded, o.minDepth, o.minDNAfreq, o.minRNAfreq, \
                o.mapq, o.bcq, o.verbose)
    p = Pool(o.threads, initializer=init_args, initargs=initargs)
    parser = p.imap(worker, regions)
    for data in parser:
        output.write("".join(info%d for d in data))
    #'''
    output.write("#Finished!\n")
    logger("Done!")
    
if __name__=='__main__': 
    t0 = datetime.now()
    try:
        main()
    except KeyboardInterrupt:
        sys.stderr.write("\nCtrl-C pressed!      \n")
    except IOError as e:
        sys.stderr.write("I/O error({0}): {1}\n".format(e.errno, e.strerror))
    dt = datetime.now()-t0
    sys.stderr.write("#Time elapsed: %s\n" % dt)
